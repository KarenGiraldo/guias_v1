{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcY9y56n86vn"
   },
   "source": [
    "# Tutorial: creación de ETLs con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcg5UCbU86vp"
   },
   "source": [
    "## 1. Introducción\t\n",
    "    ¿Qué aprenderá?\n",
    "\tEn este tutorial aprenderá cómo puede utilizar PySpark para crear un proceso de ETL básico.\n",
    "\n",
    "\t¿Qué construirá?     \n",
    "        Construirá un ETL que toma los datos desde la base de datos transacional de WideWorldImporters (WWImportersTransactional), los transforma  a una representación cercana al análisis y los  almacena en la base de datos relacional WWImportersDWH.\n",
    "    \n",
    "\t¿Para qué?\n",
    "\tLa construcción de ETLs que se ajusten a modelos multidimensionales es un paso necesario dentro de un proceso de analìtica 1.0 , pues permite tomar los datos crudos de una fuente, generalmente transaccional, para transformarlos en datos limpios que puedan utilizarse para la toma de decisiones.\n",
    "    \n",
    "    ¿Qué necesita?\n",
    "    1. Python 3 con pip instalado\n",
    "    2. Jupyter notebook\n",
    "    3. Paquetes: Pyspark (3.0.1) y pandas (1.2.1)\n",
    "    4. Controlador Connector J de MySQL (ya se encuentra instalado)\n",
    "    5. Servidor SQL con base de datos relacional \"WWImportersTransactional\" y base de datos relacional que corresponde a la bodega de WWI \"Estudiante_i\"\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqQVz5s686vq"
   },
   "source": [
    "## 2. Proceso de ETL para una dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2UT2Ia586vr"
   },
   "source": [
    "En este proceso de ETL, se extraen los datos de las **órdenes de compra** de una base de datos transaccional y se almacenan en otra base de datos que corresponde a la bodega de datos, siguiendo una aproximación ROLAP. A continuación, se presenta el modelo multidimensional que es el modelo conceptual que representa el proceso de registro de órdenes de compra. Este modelo se utilizó para crear las tablas en la bodega de datos que representan el proceso de negocio y que serán cargadas como resultado del proceso ETL. \n",
    "\n",
    "Tenga en cuenta que las llaves ID_XXXX presentes en el modelo hacen referencia a las llaves de la bodega. Por otra parte, en el proceso de ETL se van a tener en cuenta las llaves transaccionales (**WWImportersTransactional**). La nomenclatura para utilizar es:\n",
    "\n",
    "1.   ID_XXXX_DWH, para las llaves de la bodega.\n",
    "2.   ID_XXXX_T, para las llaves transaccionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpOSEfhX86vs"
   },
   "source": [
    "![Modelo ordenes](./WWI_modelo_ordenes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rg1M_rdU86vs"
   },
   "source": [
    "El proceso de ETL debe ser diseñado antes de implementarse. A partir de las conclusiones del entendimiento de datos sabemos las fuentes que se van a  utilizar y la relación entre las fuentes. Adicionalmente, se cuenta con las respuestas de la organización a las preguntas, resultado del entendimiento de datos. De esa manera sabemos cómo se deben manipular los datos. \n",
    "\n",
    "Este proceso de ETL lo dividimos en seis bloques, uno para cada dimensión o <i>tabla de hechos</i> del modelo, con la única excepción de la dimensión de fecha que, por ser una dimensión especial que se genera de forma independiente, no se incluye aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIa8WW1M86vt"
   },
   "source": [
    "![ETL](./Disenio_ETL.PNG)\n",
    "\n",
    "Recuerde que este es el diseño general. En el diseño completo se deben incluir las transformaciones realizadas a los datos a utilizarse en las dimensiones y tablas de hecho del modelo multidimensional, de acuerdo con lo que se muestra en la infografía de arquitectura de componentes (Componente proceso ETL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "os1iJYmu86vt"
   },
   "outputs": [],
   "source": [
    "# Configuración servidor base de datos transaccional\n",
    "# Recuerde usar Estudiante_i como usuario y la contraseña asigana en el excel de conexión a maquina virtual como contraseña\n",
    "db_user = 'Estudiante_19_202413'\n",
    "db_psswd = 'aabb1122'\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/WWImportersTransactional'\n",
    "\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/Estudiante_19_202413'\n",
    "\n",
    "# Driver de conexion\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HAGk_V1986vu"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TQ3DM_Xf86vv",
    "outputId": "f2cdb157-a92d-4edc-a174-6f3bd09b9885"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estudiante\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "#Configuración de la sesión\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buA7s-vL86vw"
   },
   "source": [
    "### Conexión y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_QZ-j9q86vw"
   },
   "source": [
    "Se define la función para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mhy0jbh_86vw"
   },
   "outputs": [],
   "source": [
    "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFsv4ba86vw"
   },
   "source": [
    "### BLOQUE 1\n",
    "Empezamos con el bloque 1: la dimensión <i>Empleado</i>, su fuente de datos viene de la tabla transaccional <i>Personas</i>. En la sentencia SQL filtramos usando WHERE para seleccionar solo las personas que sean vendedores y recuperamos únicamente los atributos que queremos, de acuerdo con  modelo dimensional. Recuerde que también puede usar el **.select()** de pyspark si no conoce los atributos de las tablas transaccionales. Sin embargo, es más eficiente aplicar el filtro en la consulta, ya que no trae a memoria más información de la necesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNKxFA-f86vx"
   },
   "source": [
    "#### Extracción\n",
    "A continuación, nos conectamos a la base de datos y extraemos la información deseada por medio de SQL, cargandola en un DataFrame PySpark, es decir en memoria. Note que aquí se pueden renombrar los atributos con la estructura <i>nombreActual AS nuevoNombre</i>. De la tabla de personas, En este paso, solo nos interesan los empleados, por lo cual se hace un filtro por medio del WHERE, buscando las personas cuyo atributo EsVendedor sea igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IopBNYuc86vx",
    "outputId": "0589f8a9-527e-4b28-d096-a176efd48e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+----------+\n",
      "|ID_Empleado|            Nombre|EsVendedor|\n",
      "+-----------+------------------+----------+\n",
      "|          2|    Kayla Woodcock|      true|\n",
      "|          3|     Hudson Onslow|      true|\n",
      "|          6|     Sophia Hinton|      true|\n",
      "|          7|         Amy Trefl|      true|\n",
      "|          8|    Anthony Grosse|      true|\n",
      "|         13|Hudson Hollinworth|      true|\n",
      "|         14|         Lily Code|      true|\n",
      "|         15|         Taj Shand|      true|\n",
      "|         16|     Archer Lamble|      true|\n",
      "|         20|       Jack Potter|      true|\n",
      "+-----------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_empleados = '''(SELECT DISTINCT ID_persona AS ID_Empleado, NombreCompleto AS Nombre, EsVendedor FROM WWImportersTransactional.Personas WHERE EsVendedor=1) AS Temp_empleados'''\n",
    "empleados = obtener_dataframe_de_bd(source_db_connection_string, sql_empleados, db_user, db_psswd)\n",
    "empleados.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtE61qk986vx"
   },
   "source": [
    "#### Transformación\n",
    "Recuerde que, puede hacer uso de selectExpr, filter, where entre otras de PySpark para modificar los datos cargados. Por ejemplo, el siguiente código utiliza <i>selectExpr</i> para renombrar la columna ID_Empleado por ID_Empleado_T, esta es la convención que vamos a utilizar: \"_T\" para indicar que el ID es el que estaba en la base de datos transaccional y \"_DWH\" para indicar que son ID's propios de la bodega. Usamos withColumn y monotonicallu_increasing_id para crear un ID acumulativo para cada registro en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------+\n",
      "|ID_Empleado_DWH|ID_Empleado_T|        Nombre|\n",
      "+---------------+-------------+--------------+\n",
      "|              1|            2|Kayla Woodcock|\n",
      "|              2|            3| Hudson Onslow|\n",
      "|              3|            6| Sophia Hinton|\n",
      "|              4|            7|     Amy Trefl|\n",
      "|              5|            8|Anthony Grosse|\n",
      "+---------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "empleados = empleados.selectExpr('ID_Empleado as ID_Empleado_T','Nombre')\n",
    "empleados = empleados.coalesce(1).withColumn('ID_Empleado_DWH', f.monotonically_increasing_id() + 1)\n",
    "empleados = empleados.select('ID_Empleado_DWH','ID_Empleado_T','Nombre')\n",
    "empleados.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Oou0g986vy"
   },
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino\n",
    "\n",
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qICUWYCa86vy"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, empleados,'Estudiante_19_202413.Empleados', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6k37LtO86vy"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvj5E1GS86vz"
   },
   "source": [
    "### BLOQUE 2\n",
    "Empezamos el bloque 2: dimensión ciudad. Su fuente de datos es una combinación de las tablas transaccionales <i>paises, provinciasEstados y ciudades</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5kFkHTD86vz"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FEW2mcMn86vz",
    "outputId": "a18be86c-fd81-4b56-de5c-bec1f41db118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_ciudad_T', 'NombreCiudad', 'ID_EstadoProvincia', 'Poblacion'] ['ID_Pais', 'Nombre', 'Continente', 'Region', 'Subregion'] ['ID_EstadoProvincia', 'NombreEstadoProvincia', 'TerritorioVentas', 'ID_Pais']\n"
     ]
    }
   ],
   "source": [
    "#EXTRACCION\n",
    "sql_paises = '''(SELECT DISTINCT ID_Pais, Nombre, Continente, Region, Subregion FROM WWImportersTransactional.Paises) AS Temp_paises'''\n",
    "sql_provincias_estados = '''(SELECT DISTINCT ID_EstadosProvincias AS ID_EstadoProvincia, NombreEstadoProvincia, TerritorioVentas, ID_Pais FROM WWImportersTransactional.EstadosProvincias) AS Temp_estados_provincias'''\n",
    "sql_ciudades = '''(SELECT DISTINCT ID_ciudad as ID_ciudad_T, NombreCiudad, ID_EstadoProvincia, Poblacion FROM WWImportersTransactional.Ciudades) AS Temp_ciudades'''\n",
    "\n",
    "paises = obtener_dataframe_de_bd(source_db_connection_string, sql_paises, db_user, db_psswd)\n",
    "provincias_estados = obtener_dataframe_de_bd(source_db_connection_string, sql_provincias_estados, db_user, db_psswd)\n",
    "ciudades = obtener_dataframe_de_bd(source_db_connection_string, sql_ciudades, db_user, db_psswd)\n",
    "\n",
    "print(ciudades.columns, paises.columns, provincias_estados.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddFhEOmL86vz"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8un2p4so86v0",
    "outputId": "ba2758d9-aca3-4198-c13c-514bdbf51061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "|ID_Ciudad_DWH|ID_ciudad_T|NombreCiudad|   Continente|         Pais|Poblacion|  Region|TerritorioVentas|NombreEstadoProvincia|       Subregion|\n",
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "|            1|         49|     Absecon|North America|United States|     8411|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            2|        150|    Adelphia|North America|United States|     null|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            3|        336|      Albion|North America|United States|     null|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            4|        458|   Allamuchy|North America|United States|       78|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            5|        480|   Allendale|North America|United States|     6505|Americas|         Mideast|           New Jersey|Northern America|\n",
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "ciudades = ciudades.join(provincias_estados, how = 'left', on = 'ID_EstadoProvincia')\n",
    "ciudades = ciudades.join(paises, how = 'left', on = 'ID_Pais')\n",
    "ciudades = ciudades.coalesce(1).withColumn('ID_Ciudad_DWH', f.monotonically_increasing_id() + 1)\n",
    "ciudades = ciudades.select('ID_Ciudad_DWH','ID_ciudad_T','NombreCiudad','Continente','Nombre','Poblacion',\n",
    "                          'Region','TerritorioVentas','NombreEstadoProvincia','Subregion') \\\n",
    "                    .withColumnRenamed('Nombre','Pais')\n",
    "ciudades.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuvVgJ4R86v0"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yCC2zZqY86v0"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column \"ID_Ciudad_DWH\" not found in schema Some(StructType(StructField(ID_Ciudad,IntegerType,false), StructField(Nombre,StringType,true), StructField(Continente,StringType,true), StructField(Pais,StringType,true), StructField(Población,IntegerType,true), StructField(Region,StringType,true), StructField(Territorio_ventas,StringType,true), StructField(Estado_provincia,StringType,true), StructField(Subregion,StringType,true)))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\3952221175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CARGUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mguardar_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mciudades\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Estudiante_19_202413.Ciudad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\211298303.py\u001b[0m in \u001b[0;36mguardar_db\u001b[1;34m(db_connection_string, df, tabla, db_user, db_psswd)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1322\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column \"ID_Ciudad_DWH\" not found in schema Some(StructType(StructField(ID_Ciudad,IntegerType,false), StructField(Nombre,StringType,true), StructField(Continente,StringType,true), StructField(Pais,StringType,true), StructField(Población,IntegerType,true), StructField(Region,StringType,true), StructField(Territorio_ventas,StringType,true), StructField(Estado_provincia,StringType,true), StructField(Subregion,StringType,true)))"
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, ciudades,'Estudiante_19_202413.Ciudad', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fo-J97586v0"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HpgwA6t86v0"
   },
   "source": [
    "### BLOQUE 3\n",
    "Bloque 3: dimensión paquete. Su fuente de datos es la tabla transaccional <i>Paquetes</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjDeVYd86v1"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2HTzU96W86v1"
   },
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_paquetes = '''(SELECT DISTINCT ID_TipoPaquete AS ID_TipoPaquete_T, TipoPaquete AS Nombre FROM WWImportersTransactional.Paquetes) AS Temp_Paquetes'''\n",
    "paquetes = obtener_dataframe_de_bd(source_db_connection_string, sql_paquetes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7xbgfCk86v1"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "97vmyl3Q86v1",
    "outputId": "0ffd3364-9b73-4001-e9bf-de53c97a2b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------+\n",
      "|ID_TipoPaquete_DWH|ID_TipoPaquete_T|Nombre|\n",
      "+------------------+----------------+------+\n",
      "|                 1|               1|   Bag|\n",
      "|                 2|               2| Block|\n",
      "|                 3|               3|Bottle|\n",
      "|                 4|               4|   Box|\n",
      "|                 5|               5|   Can|\n",
      "+------------------+----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "paquetes = paquetes.coalesce(1).withColumn('ID_TipoPaquete_DWH', f.monotonically_increasing_id() + 1)\n",
    "paquetes = paquetes.select('ID_TipoPaquete_DWH','ID_TipoPaquete_T','Nombre')\n",
    "paquetes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_102Yy86v1"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UpbxgpWn86v1"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column \"ID_TipoPaquete_DWH\" not found in schema Some(StructType(StructField(ID_TipoPaquete,IntegerType,false), StructField(Nombre,StringType,true)))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\2582436813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CARGUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mguardar_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaquetes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Estudiante_19_202413.TipoPaquete'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\211298303.py\u001b[0m in \u001b[0;36mguardar_db\u001b[1;34m(db_connection_string, df, tabla, db_user, db_psswd)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1322\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column \"ID_TipoPaquete_DWH\" not found in schema Some(StructType(StructField(ID_TipoPaquete,IntegerType,false), StructField(Nombre,StringType,true)))"
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, paquetes,'Estudiante_19_202413.TipoPaquete', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTy1oE3V86v2"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYetZ2Ip86v2"
   },
   "source": [
    "### BLOQUE 4\n",
    "Bloque 4: dimensión producto, su fuente de datos es la combinación entre las tablas transaccionales Productos y Colores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HogvCqW_86v2"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZEJjQslF86v2"
   },
   "outputs": [],
   "source": [
    "sql_productos = '''(SELECT DISTINCT ID_Producto as ID_Producto_T, ID_Color, NombreProducto, Marca, Necesita_refrigeracion, Dias_tiempo_entrega, Impuesto, PrecioUnitario, PrecioRecomendado FROM WWImportersTransactional.Producto) AS Temp_productos'''\n",
    "sql_colores = '''(SELECT DISTINCT ID_Color, Color FROM WWImportersTransactional.Colores) AS Temp_colores'''\n",
    "\n",
    "productos = obtener_dataframe_de_bd(source_db_connection_string, sql_productos, db_user, db_psswd)\n",
    "colores = obtener_dataframe_de_bd(source_db_connection_string, sql_colores, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rKmT9jd86v2"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "petU8G6K86v2",
    "outputId": "34d83d0f-f557-4ded-b71e-52afb08dfaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+-----+-------+----------------------+-------------------+-----------------+--------+--------------+\n",
      "|ID_Producto_DWH|ID_Producto_T|      NombreProducto|Marca|  Color|Necesita_refrigeracion|Dias_tiempo_entrega|PrecioRecomendado|Impuesto|PrecioUnitario|\n",
      "+---------------+-------------+--------------------+-----+-------+----------------------+-------------------+-----------------+--------+--------------+\n",
      "|              1|            1|USB missile launc...| null|Missing|                     0|                 14|               37|      15|            25|\n",
      "|              2|            4|USB food flash dr...| null|Missing|                     0|                 14|               48|      15|            32|\n",
      "|              3|            5|USB food flash dr...| null|Missing|                     0|                 14|               48|      15|            32|\n",
      "|              4|            6|USB food flash dr...| null|Missing|                     0|                 14|               48|      15|            32|\n",
      "|              5|            7|USB food flash dr...| null|Missing|                     0|                 14|               48|      15|            32|\n",
      "+---------------+-------------+--------------------+-----+-------+----------------------+-------------------+-----------------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "productos = productos.join(colores, how = 'left', on = 'ID_Color').fillna({'Color': 'Missing'})\n",
    "productos = productos.coalesce(1).withColumn('ID_Producto_DWH', f.monotonically_increasing_id() + 1)\n",
    "productos = productos.select('ID_Producto_DWH','ID_Producto_T','NombreProducto','Marca','Color','Necesita_refrigeracion','Dias_tiempo_entrega','PrecioRecomendado','Impuesto','PrecioUnitario')\n",
    "productos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9SnkMUH86v3"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MMArotXz86v3"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column \"ID_Producto_DWH\" not found in schema Some(StructType(StructField(ID_Producto,IntegerType,false), StructField(Nombre,StringType,true), StructField(Marca,StringType,true), StructField(Paquete_de_compra,StringType,true), StructField(Color,StringType,true), StructField(Necesita_refrigeracion,BooleanType,true), StructField(Dias_tiempo_entrega,IntegerType,true), StructField(cantidad_por_salida,IntegerType,true), StructField(Precio_minorista_recomendado,DoubleType,true), StructField(Paquete_de_venta,StringType,true), StructField(Precio_unitario,DoubleType,true)))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\1746280488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CARGUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mguardar_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproductos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Estudiante_19_202413.Producto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\211298303.py\u001b[0m in \u001b[0;36mguardar_db\u001b[1;34m(db_connection_string, df, tabla, db_user, db_psswd)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1322\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column \"ID_Producto_DWH\" not found in schema Some(StructType(StructField(ID_Producto,IntegerType,false), StructField(Nombre,StringType,true), StructField(Marca,StringType,true), StructField(Paquete_de_compra,StringType,true), StructField(Color,StringType,true), StructField(Necesita_refrigeracion,BooleanType,true), StructField(Dias_tiempo_entrega,IntegerType,true), StructField(cantidad_por_salida,IntegerType,true), StructField(Precio_minorista_recomendado,DoubleType,true), StructField(Paquete_de_venta,StringType,true), StructField(Precio_unitario,DoubleType,true)))"
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, productos,'Estudiante_19_202413.Producto', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YglraEoA86v3"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM4L4jA086v3"
   },
   "source": [
    "### BLOQUE 5\n",
    "Bloque 5: dimensión cliente. Su fuente de datos es la combinación entre las tablas transaccionales Categorias de cliente, Grupos de compra y Clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8O1GvOd86v3"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "znROuHS086v3"
   },
   "outputs": [],
   "source": [
    "sql_categoriasCliente = '''(SELECT DISTINCT ID_Categoria, NombreCategoria FROM WWImportersTransactional.CategoriasCliente) AS Temp_categoriasclientes'''\n",
    "sql_gruposCompra = '''(SELECT DISTINCT ID_GrupoCompra, NombreGrupoCompra FROM WWImportersTransactional.GruposCompra) AS Temp_gruposcompra'''\n",
    "sql_clientes = '''(SELECT DISTINCT ID_Cliente as ID_Cliente_T, Nombre, ClienteFactura, ID_Categoria, ID_GrupoCompra, ID_CiudadEntrega, LimiteCredito, FechaAperturaCuenta, DiasPago FROM WWImportersTransactional.Clientes) AS Temp_clientes'''\n",
    "\n",
    "categoriasCliente = obtener_dataframe_de_bd(source_db_connection_string, sql_categoriasCliente, db_user, db_psswd)\n",
    "gruposCompra = obtener_dataframe_de_bd(source_db_connection_string, sql_gruposCompra, db_user, db_psswd)\n",
    "clientes = obtener_dataframe_de_bd(source_db_connection_string, sql_clientes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo633Vpg86v3"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wwK8bV8Z86v3",
    "outputId": "7b494261-1640-4108-98f8-65fbe04c7b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-----------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|           Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+-----------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             1|         803|       Bala Dixit|   Novelty Shop|          Missing|           803|           33799|         2000|2013-01-01 00:00:00|       7|\n",
      "|             2|         805|     Ratan Poddar|   Novelty Shop|          Missing|           805|           10194|         3300|2013-01-01 00:00:00|       7|\n",
      "|             3|         806|           Shi Tu|   Novelty Shop|          Missing|           806|           31685|         3000|2013-01-01 00:00:00|       7|\n",
      "|             4|         811|    Surendra Sahu|   Novelty Shop|          Missing|           811|           25332|         2100|2013-01-01 00:00:00|       7|\n",
      "|             5|         814|Johanna Hoornstra|   Novelty Shop|          Missing|           814|           26752|         2310|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+-----------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION \n",
    "# EL SUPUESTO QUE SE TIENE ES QUE TODOS LOS CLIENTES TIENEN TODOS SUS DATOS DE CATEGORIA Y GRUPO Y NO SE ESTÁN PERDIENDO CLIENTES AL REALIZAR ESTE JOIN\n",
    "clientes = clientes.join(gruposCompra, how = 'left', on = 'ID_GrupoCompra')\n",
    "clientes = clientes.alias('cl').join(categoriasCliente.alias('ct'), how = 'left', on = 'ID_Categoria') \\\n",
    ".select([col('cl.ID_Cliente_T'),col('cl.Nombre'),col('ct.NombreCategoria'),col('cl.NombreGrupoCompra') \\\n",
    "        ,col('cl.ClienteFactura'),col('cl.ID_CiudadEntrega'),col('cl.LimiteCredito'),col('cl.FechaAperturaCuenta'),col('cl.DiasPago')])\n",
    "clientes = clientes.coalesce(1).withColumn('ID_Cliente_DWH', f.monotonically_increasing_id() + 1)\n",
    "clientes = clientes.select('ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
    "                          'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago')\n",
    "\n",
    "clientes = clientes.fillna({'NombreCategoria':'Missing','NombreGrupoCompra':'Missing'})\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T| Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             0|            |Missing|        Missing|          Missing|             0|               0|             |                   |        |\n",
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crea el registro para el id = 0\n",
    "clientes_0 = [('0','','Missing','Missing','Missing','0','0','','','')]\n",
    "columns = ['ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
    "            'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago']\n",
    "cliente_0 = spark.createDataFrame(data=clientes_0,schema=columns)\n",
    "cliente_0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|            Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             1|         807|     Gunnar Lohmus|     Gift Store|          Missing|           807|           35810|         3100|2013-01-01 00:00:00|       7|\n",
      "|             2|         816|        Harsha Huq|     Gift Store|          Missing|           816|            8892|         2400|2013-01-01 00:00:00|       7|\n",
      "|             3|         823|Francisca Laureano|     Gift Store|          Missing|           823|           17142|         3500|2013-01-01 00:00:00|       7|\n",
      "|             4|         825|    Jayanta Thakur|     Gift Store|          Missing|           825|           28367|         3000|2013-01-01 00:00:00|       7|\n",
      "|             5|         828|      Sercan Celik|     Gift Store|          Missing|           828|           34193|         1785|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clientes = clientes.union(cliente_0)\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|            Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             0|            |           Missing|        Missing|          Missing|             0|               0|             |                   |        |\n",
      "|             1|         807|     Gunnar Lohmus|     Gift Store|          Missing|           807|           35810|         3100|2013-01-01 00:00:00|       7|\n",
      "|             2|         816|        Harsha Huq|     Gift Store|          Missing|           816|            8892|         2400|2013-01-01 00:00:00|       7|\n",
      "|             3|         823|Francisca Laureano|     Gift Store|          Missing|           823|           17142|         3500|2013-01-01 00:00:00|       7|\n",
      "|             4|         825|    Jayanta Thakur|     Gift Store|          Missing|           825|           28367|         3000|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se ordena por el identificador DWH\n",
    "clientes = clientes.withColumn('ID_Cliente_DWH',col('ID_Cliente_DWH').cast('int')).orderBy(col('ID_Cliente_DWH'))\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i36NawhX86v4"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QcvMzmCf86v4"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column \"ID_CiudadEntrega\" not found in schema Some(StructType(StructField(ID_Cliente_DWH,IntegerType,false), StructField(ID_Cliente_T,IntegerType,true), StructField(Nombre,StringType,true), StructField(ClienteFactura,StringType,true), StructField(ID_CiudadEntrega_DWH,IntegerType,true), StructField(LimiteCredito,DecimalType(10,2),true), StructField(FechaAperturaCuenta,DateType,true), StructField(DiasPago,IntegerType,true), StructField(NombreGrupoCompra,StringType,true), StructField(NombreCategoria,StringType,true)))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\3292895931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CARGUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mguardar_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclientes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Estudiante_19_202413.Cliente'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\211298303.py\u001b[0m in \u001b[0;36mguardar_db\u001b[1;34m(db_connection_string, df, tabla, db_user, db_psswd)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1322\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column \"ID_CiudadEntrega\" not found in schema Some(StructType(StructField(ID_Cliente_DWH,IntegerType,false), StructField(ID_Cliente_T,IntegerType,true), StructField(Nombre,StringType,true), StructField(ClienteFactura,StringType,true), StructField(ID_CiudadEntrega_DWH,IntegerType,true), StructField(LimiteCredito,DecimalType(10,2),true), StructField(FechaAperturaCuenta,DateType,true), StructField(DiasPago,IntegerType,true), StructField(NombreGrupoCompra,StringType,true), StructField(NombreCategoria,StringType,true)))"
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string,clientes,'Estudiante_19_202413.Cliente', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMyvdEB-86v4"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ocmdLWv86v4"
   },
   "source": [
    "### BLOQUE 6\n",
    "Bloque 6: Hecho orden. Su fuente de datos es la combinación entre las tablas transaccionales Ordenes y detalles de orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvgnsPfK86v4"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9b4Qs9_886v4"
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o352.load.\n: java.sql.SQLSyntaxErrorException: Table 'WWImportersTransactional.Ordenes' doesn't exist\r\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\r\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\r\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)\r\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1009)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:67)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:57)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:239)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:36)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\2090395980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msql_ordenes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'''(SELECT DISTINCT * FROM WWImportersTransactional.Ordenes) AS Temp_ordenes'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msql_detallesOrdenes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'''(SELECT DISTINCT * FROM WWImportersTransactional.DetallesOrdenes) AS Temp_detallesordenes'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mordenes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobtener_dataframe_de_bd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql_ordenes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdetallesOrdenes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobtener_dataframe_de_bd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_db_connection_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql_detallesOrdenes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\211298303.py\u001b[0m in \u001b[0;36mobtener_dataframe_de_bd\u001b[1;34m(db_connection_string, sql, db_user, db_psswd)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_psswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'driver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_bd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     def json(self, path, schema=None, primitivesAsString=None, prefersDecimal=None,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1322\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o352.load.\n: java.sql.SQLSyntaxErrorException: Table 'WWImportersTransactional.Ordenes' doesn't exist\r\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\r\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\r\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)\r\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1009)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:67)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:57)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:239)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:36)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "sql_ordenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.Ordenes) AS Temp_ordenes'''\n",
    "sql_detallesOrdenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.DetallesOrdenes) AS Temp_detallesordenes'''\n",
    "ordenes = obtener_dataframe_de_bd(source_db_connection_string, sql_ordenes, db_user, db_psswd)\n",
    "detallesOrdenes = obtener_dataframe_de_bd(source_db_connection_string, sql_detallesOrdenes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTv_CIOT86v5"
   },
   "source": [
    "#### Transformación\n",
    "Estas son las respuestas de Wide World Importers a los conclusiones obtenidas en el entendimiento de los datos:\n",
    "- La regla de negocio \"La tasa de impuesto es de 10% o 15%\" es correcta, pero habian errores en la tabla original, que fueron corregidos. \n",
    "- Para la segunda regla de negocio: \"Son 73.595 órdenes detalladas en 231.412 lineas de detalle de órdenes realizadas desde 2013\", si faltaban datos, los cuales fueron completados, y nos dicen que en cuanto a consistencia ellos revisaron las tablas e hicieron correcciones, pero que los duplicados completos de ordenes los eliminemos\n",
    "- \"El formato de fechas manejado es YYYY-MM-DD HH:MM:SS si tienen hora, minutos y segundos. De lo contrario el formato es YYYY-MM-DD\": En cuanto a formatos de fechas estan de acuerdo con que los estandarizemos y el formato sea el especificado en la regla\n",
    "- Para las descripciones de productos que eran \"a\", se actualizaron a los valores reales. \n",
    "- Se pueden eliminar las columnas Comenarios, Instrucciones_de_entrega y comentarios_internos porque estan vacias. \n",
    "- A pesar de estar en un proceso de mejorar la calidad de los datos y mantener los nulos nos ayudaría a reflejar esa calidad, de la mano con el grupo de analitica de WWI se decide imputar por la media el valor extremo de la variable Cantidad\n",
    "- Para las ordenes las columnas Seleccionado_por_ID_de_persona, ID_de_pedido_pendiente, Seleccion_completada_cuando, y para las columnas Seleccion_completada_cuando de la tabla detalles de ordenes, se decide mantener los valores vacíos, sin embargo para la variable Precio_unitario el negocio reviso y complemento los valores faltantes\n",
    "\n",
    "Las tablas usadas en el tutorial de entendimiento de datos estaran disponibles para su revision con los siguientes nombres: OrdenesCopia y DetallesOrdenesCopia. \n",
    "\n",
    "Para este tutorial vamos a trabajar con unas tablas que dadas las conclusiones del tutorial de entendimiento, WWImporters revisó los datos originales, creo tablas y las llamo \"Ordenes\" y \"DetallesOrdenes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcHdgPzj86v5"
   },
   "source": [
    "Se hace una verificación de los valores de la tasa de impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT5i7Yjq86v5",
    "outputId": "95819129-618e-4d35-dd6b-878ea1f88ce8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select(\"Tasa_de_impuesto\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI27nmvB86v5"
   },
   "source": [
    "Se hace una verificación del rango de fechas disponible en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0GmNF6x86v5",
    "outputId": "326502fa-449d-47e3-faa5-ecd2fb34651b"
   },
   "outputs": [],
   "source": [
    "ordenes.agg({\"Fecha_de_pedido\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAp83aSn86v6"
   },
   "source": [
    "Se elimina columnas Comenarios, Instrucciones_de_entrega y comentarios_internos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX2Wl4zo86v6"
   },
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop(*[\"Comentarios\", \"Instrucciones_de_entrega\",\"comentarios_internos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfONrMtq86v6"
   },
   "source": [
    "Se eliminan duplicados totales de ordenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3KbTJ4k86v6",
    "outputId": "e0783886-2dde-4a7f-f031-72d442ba87ba"
   },
   "outputs": [],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocWjOSPD86v6"
   },
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qF5L6I186v6",
    "outputId": "e2e4a3b4-025b-41b0-e7da-057df910b082"
   },
   "outputs": [],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqSCkt_V86v6"
   },
   "source": [
    "Se hace verificación de consistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXNKhNV986v7",
    "outputId": "2b6014c8-837e-4fc5-f98b-973e8899ac0f"
   },
   "outputs": [],
   "source": [
    "#consistencia: revisar genially: definicion de consistencia\n",
    "ids_ordenes = set([x.ID_de_pedido for x in ordenes.select('ID_de_pedido').collect()])\n",
    "ids_detalles = set([x.ID_de_pedido for x in detallesOrdenes.select('ID_de_pedido').collect()])\n",
    "\n",
    "len(ids_ordenes-ids_detalles), len(ids_detalles-ids_ordenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB8BrURo86v7"
   },
   "source": [
    "En el siguiente código para el manejo de fechas, pasamos del formato MM dd,YYYY al formato establecido en la regla de negocio<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajB_7vTr86v7",
    "outputId": "9cabe64a-58b5-472a-9fce-0eeedfcdb0d6"
   },
   "outputs": [],
   "source": [
    "# TRANSFORMACION\n",
    "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
    "cumplenFormato = ordenes.filter(ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "noCumplenFormato = ordenes.filter(~ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "print(noCumplenFormato.count(), cumplenFormato.count())\n",
    "print(noCumplenFormato.show(5))\n",
    "noCumplenFormato = noCumplenFormato.withColumn('Fecha_de_pedido', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d'), t.StringType())(f.col('Fecha_de_pedido')))\n",
    "ordenes = noCumplenFormato.union(cumplenFormato)\n",
    "noCumplenFormato.count(), ordenes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN-fsV5_86v7"
   },
   "source": [
    "Descripciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lPrvq2m86v7",
    "outputId": "5eb1f4eb-5b44-4753-d094-ba16ad225fd7"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.where(length(col(\"Descripcion\")) <= 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a31mBQwD86v7"
   },
   "source": [
    "Imputar valor maximo de cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAeVZ5Xc86v8",
    "outputId": "6a8395e8-cdeb-44b7-a58d-1428b6682823"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEM7tcJ986v8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes = detallesOrdenes.replace( 10000000, 360, 'Cantidad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmteyIwh86v8",
    "outputId": "79f8b8d0-b28a-42b4-c9bb-6c3eae3f537f"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uda-rfmr86v8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOcOg5wJ86v8"
   },
   "outputs": [],
   "source": [
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRyB9egF86v8"
   },
   "source": [
    "Se unen los dos dataframes en un nuevo dataframe, se verifica que no haya duplicados y si los hay se eliminan. Se crea un nuevo dataframe que va a tener toda la información del hecho orden transformada y lista para continuar el proceso de cargue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RVZ_KIj86v8",
    "outputId": "90b92db0-5f18-44a1-a14a-73ab6e1ce8f5"
   },
   "outputs": [],
   "source": [
    "ordenes_tmp =ordenes\n",
    "ordenes_tmp = ordenes_tmp.join(detallesOrdenes, how = 'inner', on = 'ID_de_pedido')\n",
    "ordenes_tmp = ordenes_tmp.withColumn('Valor_total',col('Precio_unitario')*col('Cantidad'))\n",
    "ordenes_tmp = ordenes_tmp.withColumn('Impuestos',col('Valor_total')*col('Tasa_de_impuesto'))\n",
    "ordenes_tmp = ordenes_tmp.selectExpr('ID_de_pedido as ID_de_pedido_T','ID_Producto','Fecha_de_pedido','ID_de_cliente','ID_de_vendedor','ID_Tipo_Paquete','Cantidad','Valor_total', 'Impuestos')\n",
    "\n",
    "print((ordenes_tmp.count(),ordenes_tmp.distinct().count()))\n",
    "\n",
    "ordenes_tmp = ordenes_tmp.drop_duplicates()\n",
    "ordenes_tmp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, ordenes_tmp,'Estudiante_i_XXXXXX.Hecho_Orden_Tmp', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree la tabla de Fecha según el material compartido y adicione el left join al crear la tabla de ordenes para que quede completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El idPedido representa la dimensión degenerada Pedido\n",
    "# Si hay campos nulos en ordenes_tmp al hacer join por el left outer join no se perderan y se utiliza como comodín un id=0 que debe existir en todas las dimensiones.\n",
    "# Ese comodín representa el registro sin Dato.\n",
    "# Debe adicionarle a todas las tablas el registro con identificador 0, como se muestra para la tabla de clientes\n",
    "# Recuerde que falta incluir el join con la tabla de Fecha para que la tabla quede completa.\n",
    "\n",
    "ordenes = ordenes_tmp.alias('o').join(clientes.alias('cl'), ordenes_tmp.ID_de_cliente == clientes.ID_Cliente_T,'left')\\\n",
    "                    .join(ciudades.alias('ciu'), clientes.ID_CiudadEntrega == ciudades.ID_ciudad_T,'left') \\\n",
    "                    .join(empleados.alias('e'), ordenes_tmp.ID_de_vendedor == empleados.ID_Empleado_T,'left') \\\n",
    "                    .join(paquetes.alias('p'), ordenes_tmp.ID_Tipo_Paquete == paquetes.ID_TipoPaquete_T,'left') \\\n",
    "                    .join(productos.alias('pr'), (ordenes_tmp.ID_Producto == productos.ID_Producto_T) ,'left') \\\n",
    "                    .select([col('o.ID_de_pedido_T'),col('cl.ID_Cliente_DWH'),col('ciu.ID_Ciudad_DWH'),\n",
    "                             col('e.ID_Empleado_DWH'),col('pr.ID_Producto_DWH'),col('p.ID_TipoPaquete_DWH'),\n",
    "                             col('o.Cantidad'),col('o.Valor_total'),col('o.Impuestos')]) \\\n",
    "                    .fillna({'ID_Cliente_DWH': 0, 'ID_Ciudad_DWH': 0, 'ID_Empleado_DWH': 0, 'ID_Producto_DWH': 0,\n",
    "                             'ID_TipoPaquete_DWH': 0})\n",
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes = ordenes.select('ID_de_pedido_T','ID_Ciudad_DWH','ID_Cliente_DWH','ID_Empleado_DWH','ID_Producto_DWH',\n",
    "                         'ID_TipoPaquete_DWH','Cantidad','Impuestos','Valor_total') \\\n",
    "                    .withColumnRenamed('Valor_total','Total')\n",
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9f10qpB86v9"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, ordenes,'Estudiante_i_XXXXXX.Hecho_Orden', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXk0Fxmu86v9"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWmcDXue86v9"
   },
   "source": [
    "# Resultado de consultas\n",
    "Corresponde a las consultas realizadas sobre las tablas, para mostrar el estado final de las tablas pobladas como resultado del proceso de ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGMlLaje86v9"
   },
   "source": [
    "# 3. Tarea ETL\n",
    "Espacio para desarrollar la tarea planteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwyeLpt386v9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euvEeguv86v9"
   },
   "source": [
    "## 4. Cierre\n",
    "Completado este tutorial, ya sabe cómo realizar ETL básicos en PySpark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaFNpgeW86v9"
   },
   "source": [
    "## 5. Información adicional\n",
    "\n",
    "Si quiere conocer más sobre PySpark la guía más detallada es la documentación oficial, la cual puede encontrar acá: https://spark.apache.org/docs/latest/api/python/index.html <br>\n",
    "Para ir directamente a la documentación de PySpark SQL, donde está la información sobre los DataFrames, haga clic en este enlace: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html <br>\n",
    "\n",
    "El Capítulo 2 del libro <i>Learn PySpark : Build Python-based Machine Learning and Deep Learning Models, New York: Apress. 2019</i> de Pramod Singh contiene muchos ejemplos útiles, puede encontrarlo en la biblioteca virtual de la universidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kIcwffv86v-"
   },
   "source": [
    "## 6. Preguntas frecuentes\n",
    "\n",
    "- Si al intentar escribir un <i>dataframe</i> obtiene un error en el formato: \n",
    "    ```\n",
    "    path file:<PATH>/dw/<PATH> already exists.;\n",
    "    ```\n",
    "    Borre la carpeta indicada en el error y vuelva a intentar.\n",
    "\n",
    "- Si al ejecutar su código obtiene el error: \n",
    "    ```\n",
    "    ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=tutorial ETL PySpark, master=local) created by __init__ at <ipython-input-4-64455da959dd>:92 \n",
    "\n",
    "    ```\n",
    "    reinicie el kernel del notebook y vuelva a intentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J9jYwEJ86v-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vtE61qk986vx",
    "X9Oou0g986vy",
    "B5kFkHTD86vz",
    "ddFhEOmL86vz",
    "MuvVgJ4R86v0",
    "BZjDeVYd86v1",
    "_7xbgfCk86v1",
    "Rh_102Yy86v1",
    "HogvCqW_86v2",
    "9rKmT9jd86v2",
    "R9SnkMUH86v3",
    "k8O1GvOd86v3",
    "Mo633Vpg86v3",
    "i36NawhX86v4",
    "LvgnsPfK86v4",
    "dTv_CIOT86v5",
    "N9f10qpB86v9"
   ],
   "name": "MISW-ETL-TutorialETL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
